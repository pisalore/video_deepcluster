{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"text-align:right; font-size:14px;\"> University of Studies of Florence\n",
    "<p style=\"text-align:right; font-size:14px;\"> Department of Engineering Information </p>\n",
    "<p style=\"text-align:right; font-size:14px;\"> Pistoia, April 1, 2021 </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<h1 align=center>Visual and Multimedia Recognition</h1>\n",
    "<h2 align=center>\n",
    "Unsupervised Learning with Deepcluster on VID Dataset\n",
    "</h1>\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "__AUTHOR__ = {'lp': (\"Lorenzo Pisaneschi\",\n",
    "                    \"lorenzo.pisaneschi1@stud.unifi.it\",\n",
    "                     \"https://github.com/pisalore/video_deepcluster\")}\n",
    "\n",
    "__TOPICS__ = ['Unsupervised Learning', 'Deep Learning', 'k-Means Clustering', 'AlexNet', 'Vid Dataset']\n",
    "\n",
    "\n",
    "__KEYWORDS__ = ['Python', 'Pytorch', 'AI', 'Machine Learning', 'clustering']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Introduction</h1>\n",
    "\n",
    "AI and Machine Learning algorithms are increasingly pervasive in daily life, with the result we need ever larger\n",
    "dataset and ever more annotated data for our supervised learning algorithms. For this reason, unsupervised learning is\n",
    "becoming important, in order to obtain useful information from input data to be maybe used later in a supervised learning\n",
    "process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3> Unsupervised Learning Challanges </h3>\n",
    "\n",
    "Obviously, since our algorithm does not know how the output should be, we have to evaluate if the algorithm has learnt\n",
    "something useful to our purpose. For example, using clustering algorithms, it is crucial to understand if data are\n",
    "collected in a desired way for further inference on data.\n",
    "\n",
    "<br>\n",
    "<img style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 50%;\" src=\"slides/images/img1.png\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3> Thrilling idea </h3>\n",
    "\n",
    "The following points have to be fixed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Well tested pretrained CNNs are available, like those\n",
    "obtained starting from famous ImageNet dataset, a fully supervised dataset consisting\n",
    "in one million of images distributed over 1000 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Unsupervised learning algorithms can be applied on data from any domain, and unsupervised methods\n",
    "could be applied to deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'd like to have greater dataset to perform ever complex tasks with ever more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, why not alternating clustering and convnet weights update using predicted cluster\n",
    "assignments and build a classification model in order to annotate data without\n",
    "any manual preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> Deepcluster </h1>\n",
    "\n",
    "Facebook AI research has come in help in this direction, developing a new modern approach called Deepcluster.\n",
    "\n",
    "As stated above, the main idea of deepcluster is to exploit both CNNs and clustering to create an unsupervised algorithm\n",
    "which is able to obtain useful generalized visual features.\n",
    "\n",
    "Again, the main goal is the developing of a scalable domain independent model with and end-to-end training (using both input\n",
    "and output for weights optimization).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3> How does deepclustering works? </h3>\n",
    "\n",
    "<br>\n",
    "<img style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 70%;\" src=\"slides/images/img2.png\" width=\"500\">\n",
    "\n",
    "The idea of deepcluster is simple, and it is illustrated in the figure above.\n",
    "\n",
    "1. First, features are computed using the chosen convolutional neural network.\n",
    "2. The obtained features are clustered using a clustering algorithm.\n",
    "3. The cluster assignments are then used as pseudo-labels to optimize the convent using backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3> ... a little more in detail </h3>\n",
    "\n",
    "* Given $ f_\\theta(x_n) $ the convent features mapping using an image $x_n $\n",
    "* Given the chosen clustering algorithm (k-means)\n",
    "* Given $ y_n $ as the cluster assignments and $ C $ as the centroids matrix of dimension $ d\\times k $\n",
    "\n",
    "We want to solve this problem:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\label{eq:kmeans}\n",
    "  \\min_{C \\in \\mathbb{R}^{d\\times k}}\n",
    "  \\frac{1}{N}\n",
    "  \\sum_{n=1}^N\n",
    "  \\min_{y_n \\in \\{0,1\\}^{k}}\n",
    "  \\| f_\\theta(x_n) -  C y_n \\|_2^2\n",
    "  \\quad\n",
    "  \\text{such that}\n",
    "  \\quad\n",
    "  y_n^\\top 1_k = 1.\n",
    "  \\end{align}\n",
    "$\n",
    "\n",
    "Which result is composed by cluster assignments used after as pseudo-labels.\n",
    "\n",
    "Then, weights are updated optimizing the following problem:\n",
    "\n",
    "$\\begin{align}\n",
    "\\min_{\\theta, W} \\frac{1}{N} \\sum_{n=1}^N \\ell\\left(g_W\\left( f_\\theta(x_n) \\right), y_n\\right)\n",
    "\\end{align} $\n",
    "\n",
    "Where $ \\theta $ represents the mapping parameters and $ W $ are the classifier parameters,$ g_W$ is the classifier\n",
    "and $\\ell$ is the multinomial logistic loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>Here we are!</h3>\n",
    "\n",
    "Once out deepcluster models is trained, we could use it as a \"classic\" classifier, maybe using fine tuning or\n",
    "transfer learning techniques.\n",
    "\n",
    "In this way, exploiting the pretraining with deepcluster, hopefully we could be able to generalize and automatically\n",
    "annotate our dataset of images.\n",
    "\n",
    "<br>\n",
    "<img style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\" src=\"slides/images/img3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> VID Dataset </h1>\n",
    "\n",
    "Now that the workflow of this project is clear, it is important to take a look to\n",
    "the chosen dataset.\n",
    "\n",
    "It is the VID dataset:\n",
    "* It consists of video, sampled in JPEG format frames.\n",
    "* The training set is formed by 3862 video for a total of 1.122.397 frames\n",
    "* The validation set is formed by 555 video for a total of 176.126\n",
    "* Each video belongs to one of 30 categories.\n",
    "\n",
    "Since data are derived from videos, we want to use only the part of image containing the\n",
    "object of interest. For this reason, annotations are also provided, in XML format,\n",
    "indicating object crop coordinates of the specified frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3> Data preprocessing (I)</h3>\n",
    "\n",
    "First, it is important to know our data and make a good preprocessing.\n",
    "\n",
    "* As we can imagine, not all images where correctly annotated, resulting in the need to make dataset consistent.\n",
    "\n",
    "* Another aspects involve performance: how much can an on demand crop image cost when loading data for feature computing and\n",
    "clustering using deepcluster? Does it make sense to perform the same operation on same images for many epochs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3> Data preprocessing (II)</h3>\n",
    "\n",
    "For the reasons underlined above, it is necessary to:\n",
    "\n",
    "1. Discard all not annotated images\n",
    "2. Perform an offline crop process parsing the remained consistent images XML annotations\n",
    "3. Save all the work, to make the obtained dataset always available in the process.\n",
    "\n",
    "Preprocessing is needed both for training and validation set. <br>\n",
    "With Python these operations are straightforward.\n",
    "\n",
    "<br>\n",
    "<img style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 90%;\" src=\"slides/images/img6.png\">\n",
    "\n",
    "After data preprocessing, the dataset have been sub-sampled for speed up computation, and finally it is composed by\n",
    "362.044 frames for training and 54.306 frames for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>The process: deepcluster training</h1>\n",
    "\n",
    "We are at our starting point. The framework used for this project is PyTorch.\n",
    "\n",
    "* Deepcluster was trained for 100 epochs, using a batch size of 256 and LR = 0.05.\n",
    "\n",
    "* For clustering, k-means is used. For this reason, $k$ is an important parameter to be chosen; consequently, it is also\n",
    "important to determine if a choice is better than another.\n",
    "\n",
    "* For this reason, deepcluster training was performed with three different $k$ values: 30, 150 and 300. trainings\n",
    "have been then evaluated using the NMI metric (Normalized Mutual Information):, which measures the information shared between\n",
    "two different assignments:\n",
    "\n",
    "$\\begin{align}\n",
    "\\mathrm{NMI}(A;B)=\\frac{\\mathrm{I}(A;B)}{\\sqrt{\\mathrm{H}(A) \\mathrm{H}(B)}}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "The more NMI is closer to 1, the more an assignment A is deterministically predictable from an assignment B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>Clustering stabilization</h3>\n",
    "\n",
    "<img style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\" src=\"slides/images/img7.png\">\n",
    "\n",
    "* NMI is increasing over the times, saturating ca. after 20 epochs. This fact states that there are less and less reassignments\n",
    "over the time.\n",
    "* Consequence is that dependence between clusters and labels increases over the time: features are capturing information to be\n",
    "used after in the second training phase.\n",
    "\n",
    "* With k = 300 we obtain the best performance: apparently over segmentation is beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>Clusters visualization (example for k = 300)</h3>\n",
    "\n",
    "<img style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 70%;\" src=\"slides/images/img8.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>The process: deepcluster evaluation</h1>\n",
    "\n",
    "After deepcluster training we have three models, one for each K we have used for k-means clustering.\n",
    "\n",
    "The idea now is to try to check if unsupervised training with deepcluster was\n",
    "useful for the purpose of build an images classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>Fine tuning vs Training from scratch</h3>\n",
    "\n",
    "\n",
    "<img style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\" src=\"slides/images/img9.png\">\n",
    "\n",
    "\n",
    "To do this evaluation, we can do the following:\n",
    "\n",
    "* Fine tune our models adding a  30-dimension top layer (the classifier):\n",
    "30 is the VID dataset categories number\n",
    "* Training an AlexNet from scratch using exactly the same data provided early to deepcluster (but using annotated labels)\n",
    "* Compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>Validation Loss and Accuracy</h3>\n",
    "\n",
    "<img style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 100%;\" src=\"slides/images/img10.png\">\n",
    "\n",
    "* As we can see, training with deepcluster models falls in overfitting, despite data augmentation and fine tuning. This could be\n",
    "due to the fact that images are video frames: features provides information on very similar data.\n",
    "\n",
    "* However, overfitting occurs in different moments with respect to each model. The one pretrained with 300-means performs\n",
    "better than the others; in general it seems that better the clustering phase, better the supervised training.\n",
    "\n",
    "* The previous consideration is supported by the validation accuracy plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Further steps and Conclusions</h1>\n",
    "\n",
    "Unsupervised learning is becoming more and more important since we have the need of more and more automatically annotated data.\n",
    "Indeed, unsupervised learning, at the moment, is a first step in more complex Machine Learning pipelines which are composed\n",
    "by an unsupervised phase, which outputs are used as supervised learning inputs.\n",
    "\n",
    "The work here presented is an example on how, starting from clustering, it is possible to obtain a pretrained model to be used\n",
    "as a starting point of a fine-tuned AlexNet in oder to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some future developments could be:\n",
    "* Use feature extraction instead fine tuning (using the last two convolutional layers if using AlexNet)\n",
    "* Use other architectures (for example, VGG16)\n",
    "* Use another dataset and varying the number of images during che features computing / clustering\n",
    "* Exploit video information (for VID dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center\">THANKS FOR YOUR ATTENTION !!!</h1>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}